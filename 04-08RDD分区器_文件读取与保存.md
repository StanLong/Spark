# RDD分区器

Spark 目前支持Hash 分区和 Range 分区，和用户自定义分区。Hash 分区为当前的默认分区。分区器直接决定了RDD 中分区的个数、RDD 中每条数据经过Shuffle 后进入哪个分区，进而决定了Reduce 的个数。

- 只有Key-Value 类型的RDD 才有分区器，非 Key-Value 类型的RDD 分区的值是 None
- 每个RDD 的分区 ID 范围：0 ~ (numPartitions - 1)，决定这个值是属于那个分区的。

**Hash 分区**：对于给定的 key，计算其hashCode,并除以分区个数取余

**Range** **分区**：将一定范围内的数据映射到一个分区中，尽量保证每个分区数据均匀，而且分区间有序

**自定义分区**：

```scala
package com.stanlong.spark.core.rdd.part

import org.apache.spark.{Partitioner, SparkConf, SparkContext}

object Spark01_RDD_Part {

    def main(args: Array[String]): Unit = {
        val sparkConf = new SparkConf().setMaster("local[*]").setAppName("RDD")
        val sc = new SparkContext(sparkConf)

        val rdd = sc.makeRDD(List(
            ("nba", "#######"),
            ("cba", "#######"),
            ("wnba", "#######"),
            ("nba", "#######")
        ))

        val partRdd = rdd.partitionBy(new MyPartitioner)
        partRdd.saveAsTextFile("output")

        sc.stop()

    }

    /**
     * 自定义分区
     * 1. 继承 Partitioner
     * 2. 重写方法
     */
    class MyPartitioner extends Partitioner {
        // 分区数量
        override def numPartitions: Int = 3

        // 返回数据的分区索引， 索引从0开始
        override def getPartition(key: Any): Int = {
            key match {
                case "nba" => 0
                case "wnba" => 1
                case _ => 2
            }
        }
    }

}
```

# RDD文件读取与保存

Spark 的数据读取及数据保存可以从两个维度来作区分：文件格式以及文件系统。文件格式分为：text 文件、csv 文件、sequence 文件以及Object 文件；
文件系统分为：本地文件系统、HDFS、HBASE 以及数据库。

- text 文件

- sequence 文件

  SequenceFile 文件是Hadoop 用来存储二进制形式的key-value 对而设计的一种平面文件(Flat File)。在 SparkContext 中，可以调用sequenceFile[keyClass, valueClass](path)。

- object 对象文件
  对象文件是将对象序列化后保存的文件，采用 Java 的序列化机制。可以通过objectFile[T: ClassTag](path)函数接收一个路径，读取对象文件，返回对应的 RDD，也可以通过调用saveAsObjectFile()实现

使用方式见 04-04RDD行动算子.md --》 save相关算子